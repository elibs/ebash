#!/usr/bin/env bash
#
# Copyright 2011-2021, Marshall McMullen <marshall.mcmullen@gmail.com>
# Copyright 2011-2018, SolidFire, Inc. All rights reserved.
#
# This program is free software: you can redistribute it and/or modify it under the terms of the Apache License as
# published by the Apache Software Foundation, either version 2 of the License, or (at your option) any later version.

: ${EMSG_PREFIX:=time}
: ${EBASH_HOME:=$(dirname $0)/..}
: ${EBASH:=${EBASH_HOME}/share}
source ${EBASH}/ebash.sh || { echo "Unable to source ebash." ; exit 1 ; }
export EBASH
export PATH="${PATH}:${EBASH_HOME}/bin"

# Normalize EBASH path in case any tests depend on it looking... normal. Note: wait until after sourcing so that we can
# let ebash make sure we get GNU readlink rater than BSD readlink.
EBASH_HOME=$(readlink -f "${EBASH_HOME}")
EBASH=$(readlink -f "${EBASH}")

# Save off the TOPDIR so we can easily find it even when etest is changing directories
TOPDIR=${PWD}

#-----------------------------------------------------------------------------------------------------------------------
#
# GLOBAL SETUP
#
#-----------------------------------------------------------------------------------------------------------------------

# Include all etest modules
source "${EBASH}/etest/assert.sh"
source "${EBASH}/etest/callbacks.sh"
source "${EBASH}/etest/options.sh"
source "${EBASH}/etest/results.sh"
source "${EBASH}/etest/runners.sh"
source "${EBASH}/etest/test_list.sh"

#-----------------------------------------------------------------------------------------------------------------------
#
# MAIN
#
#-----------------------------------------------------------------------------------------------------------------------

export ETEST_PID=$$

global_setup
trap_add global_teardown

# If clean only is requested exit immediately. The "clean" is done via global_setup and global_teardown.
if [[ ${clean} -eq 1 ]]; then
    exit 0
fi

# If destroy is requested then we kill all running etest instances system-wide.
#
# We nominally do this using our handy cgroup containerization if available.
# Otherwise we fall back to a more crude `pkill`.
if [[ ${destroy} -eq 1 ]]; then

    eerror "Destroying all etest instances"

    if cgroup_exists "${ETEST_CGROUP_BASE}"; then
        cgroup_kill --signal=SIGKILL ${ETEST_CGROUP_BASE}
        cgroup_destroy --recursive ${ETEST_CGROUP_BASE}
    else
        pkill -9 -f etest
    fi
fi

# Global variables for state tracking
declare -ag TEST_FILES_TO_RUN
declare -Ag TEST_FUNCTIONS_TO_RUN
declare -ag TEST_SUITES=()
declare -Ag TESTS_PASSED=()
declare -Ag TESTS_FAILED=()
declare -Ag TESTS_FLAKY=()
declare -Ag SUITE_DURATION=()
declare -Ag TESTS_DURATION=()
declare -g  NUM_TESTS_EXECUTED=0
declare -g  NUM_TESTS_PASSED=0
declare -g  NUM_TESTS_FAILED=0
declare -g  NUM_TESTS_FLAKY=0
declare -g  NUM_TESTS_TOTAL=0
declare -g  PERCENT=0

# Create initial test list and then find all matching tests
create_test_list
find_matching_tests

# If we are in print_only mode only report what we found and exit
if [[ ${print_only} -eq 1 ]]; then
    print_tests
    exit 0
fi

# If we are in print_json mode only report what we found in JSON and exit
if [[ ${print_json} -eq 1 ]]; then
    print_tests_json
    exit 0
fi

# If total timeout is requested then create a background process that will sleep that amount of time and then kill our
# main etest process.
if [[ -n "${total_timeout}" && "${total_timeout}" != "infinity" ]]; then
    (
        sleep "${total_timeout}"

        eerror "ETEST exceeded $(lval total_timeout). Killing etest."

        ekill ${ETEST_PID}

        if cgroup_exists ${ETEST_CGROUP}; then
            cgroup_kill --signal=SIGKILL ${ETEST_CGROUP}
            cgroup_destroy --recursive ${ETEST_CGROUP}
        fi

        exit 124

    ) &>/dev/null &

    watcher_pid=$!

    trap_add "ekill ${watcher_pid} &>/dev/null" EXIT
fi

# Create logfile
elogrotate "${ETEST_JSON}"
elogrotate "${ETEST_OPTIONS}"
elogrotate "${ETEST_XML}"
if [[ ${jobs} -eq 0 ]]; then
    elogfile --rotate_count=10 --tail=${verbose} ${ETEST_LOG}
else
    elogfile --rotate_count=10 --tail=0 /dev/null
fi
create_status_json

# Run all tests the requested number of times
for (( ITERATION=1; ITERATION<=${repeat}; ITERATION++ )); do
    REPEAT_STRING="${ITERATION}/${repeat}"
    run_all_tests
done

# Collect and report results
DURATION=$(( SECONDS - START_TIME ))
create_summary
create_xml

exit ${NUM_TESTS_FAILED}
