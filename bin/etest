#!/usr/bin/env bash
#
# Copyright 2011-2021, Marshall McMullen <marshall.mcmullen@gmail.com>
# Copyright 2011-2018, SolidFire, Inc. All rights reserved.
#
# This program is free software: you can redistribute it and/or modify it under the terms of the Apache License as
# published by the Apache Software Foundation, either version 2 of the License, or (at your option) any later version.

: ${EMSG_PREFIX:=time}
: ${EBASH_HOME:=$(dirname $0)/..}
: ${EBASH:=${EBASH_HOME}/share}
source ${EBASH}/ebash.sh || { echo "Unable to source ebash." ; exit 1 ; }
export EBASH
export PATH="${PATH}:${EBASH_HOME}/bin"

if [[ ${EBASH_OS} == "Linux" ]] ; then
    reexec --sudo
fi

# Normalize EBASH path in case any tests depend on it looking... normal. Note: wait until after sourcing so that we can
# let ebash make sure we get GNU readlink rater than BSD readlink.
EBASH_HOME=$(readlink -f "${EBASH_HOME}")
EBASH=$(readlink -f "${EBASH}")

# Save off the TOPDIR so we can easily find it even when etest is changing directories
TOPDIR=${PWD}

#-----------------------------------------------------------------------------------------------------------------------
#
# GLOBAL SETUP
#
#-----------------------------------------------------------------------------------------------------------------------

opt_usage main <<'END'
etest is an extensible test framework primarily focused at providing a rich test framework for bash complete with test
suites and a rich set of test assertions and other various test related frameworks. It also supports running any
standalone executable binaries or scripts written in any language. In this mode it is essentially a simple test driver.

Tests can be grouped into test suites by placing them into a *.etest file. Each test is then a function inside that file
with the naming scheme `ETEST_${suite}_${testcase}` (e.g. `ETEST_array_init` for the `array` suite and the testcase
`init`). Each test suite *.etest file can contain optional `sutie_setup` and `suite_teardown` functions which are
performed only once at the start and end of a suite, respectively. It can also optionally contain `setup` and
`teardown` functions which are run before and after every single individual test.

etest provides several additional security and auditing features of interest:

    1) Every test is run in its own subshell to ensure process isolation.
    2) Every test is run inside a unique cgroup (on Linux) to further isolate the process, mounts and networking from
       the rest of the system.
    3) Each test is monitored for process leaks and mount leaks.

Tests can be repeated, filtered, excluded, debugged, traced and a host of other extensive developer friendly features.

etest produces a JUnit/XUnit compatible etest.xml file at the end of the test run listing all the tests that were
executed along with runtimes and specific lists of passing, failing and flaky tests. This file can be directly hooked
into Jenkins, GitHub Actions, and BitBucket Pipelines for clear test visibility and reporting.
END
: ${FAILFAST:=${BREAK:-0}}
$(opt_parse \
    "+failfast break b=${FAILFAST} | Stop immediately on first failure."                                               \
    "+clean   c=0                  | Clean only and then exit."                                                        \
    ":debug   D=${EDEBUG:-}        | EDEBUG output."                                                                   \
    "+delete  d=1                  | Delete all output files when tests complete."                                     \
    ":name                         | Name of this test run to use for artifacts and display purposes (default=etest)." \
    "+print_only print p           | Print list of tests that would be executed based on provided filter and exclude
                                     to stdout and then exit without actually running any tests."                      \
    ":exclude x                    | Tests whose name or file match this regular expression will not be run."          \
    ":failures=${FAILURES:-0}      | Number of failures per-test to permit. Normally etest will return non-zero if any
                                     test fails at all. However, in certain circumstances where flaky tests exist it may
                                     be desireable to allow each test to retried a specified number of times and only
                                     classify it as a failure if that test fails more than the requested threshold."   \
    ":filter  f                    | Tests whose name or file match this (bash-style) regular expression will be run." \
    "+html    h=0                  | Produce an HTML logfile and strip color codes out of etest.log."                  \
    ":jobs    j=0                  | Number of parallel jobs to run. If this is greater than 0, then the output will
                                     show a progress bar to monitor the parallel jobs. There will be a separate state
                                     directory for each job available in the jobs subdirectory under work directory.
                                     Note that a value of 0 disables parallel job execution. A value of 1 only runs a
                                     single job at a time but allows execution of the parallel job code paths. This
                                     is useful as it allows consistency for the caller to just pass the value of nproc
                                     into etest and the results and output will be identical."                         \
    ":jobs_delay=5s                | Amount of time to sleep in job monitor while waiting for jobs to complete. This
                                     uses sleep(1) time syntax."                                                       \
    "+jobs_progress=1              | Show jobs eprogress summary ticker while running."                                \
    ":logdir log_dir               | Directory to place logs in. Defaults to the current directory."                   \
    "+mount_ns=1                   | Run tests inside a mount namespace."                                              \
    ":repeat  r=${REPEAT:-1}       | Number of times to repeat each test."                                             \
    "+summary s=0                  | Display final summary to terminal in addition to logging it to etest.json."       \
    "&test_list l                  | File that contains a list of tests to run. This file may contain comments on lines
                                     that begin with the # character. All other nonblank lines will be interpreted as
                                     things that could be passed as @tests -- directories, executable scripts, or .etest
                                     files. Relative paths will be interpreted against the current directory. This
                                     option may be specified multiple times."                                          \
    "+verbose v=${VERBOSE:-0}     | Verbose output."                                                                   \
    ":workdir work_dir            | Temporary location where etest can place temporary files. This location will be both
                                    created and deleted by etest."                                                     \
    ":timeout=infinity            | Per-Test timeout. After this duration the test will be killed if not completed. You
                                    can also define this programmatically in setup() using the ETEST_TIMEOUT variable.
                                    This uses sleep(1) time syntax."                                                   \
    ":total_timeout=infinity      | Total test timeout for entire etest run. This is different than timeout which is for
                                    a single unit test. This is the total timeout for ALL test suites and tests being
                                    executed. After this duration etest will be killed if it has not completed. This
                                    uses sleep(1) time syntax."                                                        \
    "+subreaper=1                 | On Linux, set the CHILD_SUBREAPER flag so that any processes created by etest get
                                    reparented to etest itself instead of to init or whatever process ancestor may have
                                    set this flag. This allows us to properly detect process leak detections and ensure
                                    they are cleaned up properly. This only works on Linux with gdb installed."       \
    "@tests                       | Any number of individual tests, which may be executables to be executed and checked
                                    for exit code or may be files whose names end in .etest, in which case they will be
                                    sourced and any test functions found will be executed. You may also specify
                                    directories in which case etest will recursively find executables and .etest files
                                    and treat them in similar fashion."                                                \
)

# Verify --jobs is a valid integer.
if ! is_int "${jobs}" || ! assert_num_ge "${jobs}" 0; then
    die "jobs must be an integer value greater than or equal to 0"
fi

# Use mount namespaces as long as:
#   1) they weren't forcibly turned off
#   2) we're on linux
#   3) we're not inside docker (because docker requires us to be privileged, and because the benefit is no longer there
#      -- docker already protects us inside a mount namespace)
if [[ ${mount_ns} -eq 1 ]] && os linux && ! running_in_docker; then
    reexec --mount-ns
fi

# On Linux, if requested, set the CHILD_SUBREAPER flag so that any processes created by etest get reparented to etest.
# This allows us to properly detect process leaks and ensure they are cleaned up properly.
#
# NOTE: There is no native bash way to make system calls. But we can do it through GDB. This may be worth abstracting
# into a module to allow calling system calls in bash natively.
#
if [[ ${subreaper} -eq 1 ]]; then

    if ! os linux; then
        edebug "Subreaper disabled (non-Linux)"
    elif ! command_exists gdb; then
        edebug "Subreaper disabled (gdb missing)"
    else
        gdb -batch -ex 'call (int)prctl((int)36,(long)1,(long)0,(long)0,(long)0)' -ex detach -ex quit -p $$ |& edebug
        trap "" SIGTERM
    fi
fi

declare -A _EBASH_CONF
if [[ -f .ebash ]] ; then
    conf_read _EBASH_CONF .ebash
fi

START_TIME=${SECONDS}

# Default log directory from conf file if unspecified on the command line
: ${logdir:=$(conf_get _EBASH_CONF etest.log_dir)}
: ${logdir:=$(conf_get _EBASH_CONF etest.logdir)}
: ${logdir:=.}
logdir=$(readlink -f ${logdir})

# Layer the filter setting by first looking for any static filter settings in the config file, then any explicit filter
# options passed in on the command-line. Join any whitespace with a '|' to convert it to a bash style regex.
base_filter=$(conf_get _EBASH_CONF etest.filter)
: ${filter:=${FILTER:-}}
filter=$(echo "${base_filter} ${filter}" | tr ' ' '|' | sed -e 's/^|//' -e 's/|$//')

# Layer the exclude setting by first looking for any static exclusions in the config file, then any explicit exclusions
# passed in on the command-line. Join any whitespace with a '|' to convert it to a bash style regex.
base_exclude=$(conf_get _EBASH_CONF etest.exclude)
: ${exclude:=${EXCLUDE:-}}
exclude=$(echo "${base_exclude} ${exclude}" | tr ' ' '|' | sed -e 's/^|//' -e 's/|$//')

# Layer the list of tests by first looking for any static tests in the config file, then any explicit tests
# passed in on the command-line. Append all of these into a single array.
tests+=( $(conf_get _EBASH_CONF etest.tests) )
if array_not_empty test_list ; then
    # Read non-comment lines from test_list and treat them as if they were passed as arguments to this script
    edebug "Grabbing test list from $(lval test_list)"
    array_init_nl tests_from_list "$(grep -vP '^\s*(#.*)$' "${test_list[@]}")"
    if array_not_empty tests_from_list ; then
        edebug "Found $(lval test_list tests_from_list)"
        tests+=( "${tests_from_list[@]}" )
    else
        edebug "Found no tests in $(lval test_list)"
    fi
fi

# Default working directory from conf file if unspecified, or ./output if not in either place
: ${workdir:=$(conf_get _EBASH_CONF etest.work_dir)}
: ${workdir:=$(conf_get _EBASH_CONF etest.workdir)}
: ${workdir:=./output}
mkdir -p "${workdir}"
workdir=$(readlink -f ${workdir})

EDEBUG=${debug}

(( ${repeat} < 1 )) && repeat=1
[[ ${EDEBUG:-0} != "0" || ${print_only} -eq 1 ]] && verbose=1 || true
edebug "$(lval TOPDIR TEST_DIR) $(opt_dump)"

if ! cgroup_supported ; then
    export ETEST_CGROUP_BASE=unsupported
else
    # Global cgroup name for all unit tests run here
    export ETEST_CGROUP_BASE="etest"
fi
export ETEST_CGROUP="${ETEST_CGROUP_BASE}/$$"

# Setup logfile
exec {ETEST_STDERR_FD}<&2
artifact_name="$(echo "${logdir}/${name:-etest}" | tr ' ' '_')"
ETEST_LOG="${artifact_name}.log"
ETEST_JSON="${artifact_name}.json"
ETEST_XML="${artifact_name}.xml"

elogrotate "${ETEST_JSON}"
elogrotate "${ETEST_XML}"
elogfile --rotate_count=10 --tail=${verbose} ${ETEST_LOG}

# Setup redirection for "etest" and actual "test" output
if [[ ${verbose} -eq 0 ]]; then
    ETEST_OUT="$(fd_path)/${ETEST_STDERR_FD}"
    TEST_OUT="/dev/null"
else
    ETEST_OUT="/dev/null"
    TEST_OUT="/dev/stderr"
fi

#-----------------------------------------------------------------------------------------------------------------------
#
# TEST ASSERTIONS
#
#-----------------------------------------------------------------------------------------------------------------------

die_handler()
{
    $(opt_parse \
        ":rc return_code r=1 | Return code that die will exit with")

    # Append any error message to logfile
    if [[ ${verbose} -eq 0 ]]; then
        echo "" >&2
        eerror "${@}"

        # Call eerror_stacktrace but skip top three frames to skip over the frames containing stacktrace_array,
        # eerror_stacktrace and die itself. Also skip over the initial error message since we already displayed it.
        eerror_stacktrace -f=4 -s

    fi &>>${ETEST_OUT}

    exit ${rc}
}

assert_no_process_leaks()
{
    if ! cgroup_supported; then
        return 0
    fi

    edebug "Checking for process leaks in ${ETEST_CGROUP}"

    if ! cgroup_exists "${ETEST_CGROUP}"; then
        edebug "$(lval ETEST_CGROUP) does not exist -- returning"
        return 0
    fi

    # Check if any processes leaked. Check quickly to avoid unecessary delays at clean-up time. If there are any
    # leaked processes remaining, THEN do an eretry to give them time to shutdown. Finally, assert that there are none
    # left.
    try
    {
        eretry -T=5s cgroup_empty "${ETEST_CGROUP}"
    }
    catch
    {
        local leaked_processes=""
        leaked_processes=$(cgroup_ps "${ETEST_CGROUP}")

        if [[ -n ${leaked_processes} ]]; then
            cgroup_kill_and_wait -s=SIGKILL "${ETEST_CGROUP}"
            eerror "Leaked processes in ${ETEST_CGROUP}:\n${leaked_processes}"
            return 1
        fi
    }

    edebug "Finished checking for process leaks in ${ETEST_CGROUP}"
}

assert_no_mount_leaks()
{
    local mounts=()
    mounts=( $(efindmnt "${workdir}" ) )

    if ! array_empty mounts; then
        eunmount --all --recursive --delete=${delete} "${workdir}"
        eerror "Leaked under $(lval mounts workdir)"$'\n'"$(array_join_nl mounts)"
        return 1
    fi

    if [[ ${delete} -eq 1 ]]; then
        rm --recursive --force "${workdir}"
    fi

    edebug "Finished"
}

#-----------------------------------------------------------------------------------------------------------------------
#
# GLOBAL SETUP / TEARDOWN
#
#-----------------------------------------------------------------------------------------------------------------------

global_setup()
{
    ecolor hide_cursor &>>${ETEST_OUT}
    edebug "Running global_setup"

    # Create a specific directory to run this test in. That way the test can create whatever directories and files it
    # needs and assuming the test succeeds we'll auto remove the directory after the test completes.
    efreshdir "${workdir}"

    # If cgroups are supported, create a new parent cgroup which will contain all our processes including the elogfile
    # processes we already launched.
    if cgroup_supported ; then
        cgroup_create ${ETEST_CGROUP}
        cgroup_move ${ETEST_CGROUP_BASE} $$ $(elogfile_pids)
    fi

    edebug "Finished global_setup"
}

global_teardown()
{
    ecolor show_cursor &>>${ETEST_OUT}

    edebug "Running global_teardown: PID=$$ BASHPID=${BASHPID} PPID=${PPID}"

    # Try to clean up any lingering process leaks or mount leaks but do not fail here as we need to perform additional
    # cleanup after this.
    try
    {
        assert_no_process_leaks
        assert_no_mount_leaks
    }
    catch
    {
        eerror "Unexpected leaked processes or mount leaks in global_teardown"
    }

    # Convert logfile to HTML if requested
    if [[ ${html} -eq 1 ]] && which ansi2html &>/dev/null; then
        edebug "Converting ${ETEST_LOG} into HTML"
        cat ${ETEST_LOG} | ansi2html --scheme=xterm > ${ETEST_LOG/.log/.html}
        noansi ${ETEST_LOG}
    fi

    edebug "Finished global_teardown"

    # Gracefully stop elogfile
    elogfile_kill --all

    # Destroy parent cgroup
    if cgroup_supported ; then
        cgroup_destroy --recursive ${ETEST_CGROUP}
    fi
}

#-----------------------------------------------------------------------------------------------------------------------
#
# TEST RUNNERS
#
#-----------------------------------------------------------------------------------------------------------------------

run_single_test()
{
    $(opt_parse \
        ":testidx       | Test index of current test. Mose useful if the test is a function inside a test suite." \
        ":testidx_total | Total number of tests. Most useful if the test is a function inside a test suite." \
        ":testdir       | Temporary directory that the test should use as its current working directory." \
        ":source        | Name of the file to be sourced in the shell that will run the test. Most useful if the test is
                          a function inside that file." \
        "testname       | Command to execute to run the test")

    local rc=0

    # Record start time of the test and at the end of the test we'll update the total runtime for the test. This will
    # be total runtime including any suite setup, test setup, test teardown and suite teardown.
    local start_time="${SECONDS}"

    local display_testname=${testname}
    if [[ -n ${source} ]] ; then
        display_testname="${source}:${testname}"
    fi

    local index_string="${testidx}/${testidx_total}"
    ebanner --uppercase "${testname}" OS debug exclude failfast failures filter jobs repeat=REPEAT_STRING INDEX=index_string timeout total_timeout verbose

    # If this file is being sourced then it's an ETEST so log it as a subtest via einfos. Otherwise log via einfo as a
    # top-level test script.
    local einfo_message einfo_message_length
    if [[ -n "${source}" ]]; then
        einfo_message=$(einfos -n "${testname#ETEST_}" 2>&1)
    else
        einfo_message=$(EMSG_PREFIX="" einfo -n "${testname}" 2>&1)
    fi

    echo -n "${einfo_message}" &>>${ETEST_OUT}
    einfo_message_length=$(echo -n "${einfo_message}" | noansi | wc -c)

    increment NUM_TESTS_EXECUTED

    local suite
    if [[ -n "${source}" ]]; then
        suite="$(basename "${source}" ".etest")"
    else
        suite="$(basename "${testname}")"
    fi

    local tries=0
    for (( tries=0; tries <= ${failures}; tries++ )); do

        rc=0

        # We want to make sure that any traps from the tests execute _before_ we run teardown, and also we don't want
        # the teardown to run inside the test-specific cgroup. This subshell solves both issues.
        try
        {
            export EBASH EBASH_HOME TEST_DIR_OUTPUT=${testdir}
            if [[ -n ${source} ]] ; then
                source "${source}"

                # If the test name we were provided doesn't exist after sourcing this script then there is some
                # conditional in the test that is designed to prevent us from running it so we should simply return.
                if ! is_function ${testname}; then
                    edebug "Skipping $(lval source testname)"
                    return 0
                fi
            fi

            # Pretend that the test _not_ executing inside a try/catch so that the error stack will get printed if part
            # of the test fails, as if etest weren't running it inside a try/catch
            __EBASH_INSIDE_TRY=0

            # Create our temporary workspace in the directory specified by the caller
            efreshdir "${testdir}"
            mkdir "${testdir}/tmp"
            TMPDIR="$(readlink -m ${testdir}/tmp)"
            export TMPDIR

            if cgroup_supported; then
                cgroup_create ${ETEST_CGROUP}
                cgroup_move ${ETEST_CGROUP} ${BASHPID}
            fi

            # Determine the command that etest needs to run.
            # Also set ETEST_COMMAND in case caller wants to know what command is being run inside Setup or suite_setup, etc.
            local command="${testname}"
            if ! is_function "${testname}" ; then
                command="${PWD}/${testname}"
            fi
            ETEST_COMMAND="${command}"

            cd "${testdir}"

            # Run suite setup function if provided and we're on the first test.
            if is_function suite_setup && [[ ${testidx} -eq 0 ]]; then
                etestmsg "Running suite_setup $(lval testidx testidx_total)"
                suite_setup
            fi

            # Run optional test setup function if provided
            if is_function setup ; then
                etestmsg "Running setup"
                setup
            fi

            : ${ETEST_TIMEOUT:=${timeout}}
            : ${ETEST_JOBS:=${jobs}}
            etestmsg "Running $(lval command tries failures testidx testidx_total timeout=ETEST_TIMEOUT jobs=ETEST_JOBS)"

            if [[ -n "${ETEST_TIMEOUT}" && "${ETEST_TIMEOUT}" != "infinity" ]]; then
                etimeout --timeout="${ETEST_TIMEOUT}" "${command}"
            else
                "${command}"
            fi

            # Run optional test teardown function if provided
            if is_function teardown ; then
                etestmsg "Running teardown"
                teardown
            fi

            # Run suite teardown function if provided and we're on the last test
            if is_function suite_teardown && [[ ${testidx} -eq ${testidx_total} ]]; then
                etestmsg "Running suite_teardown $(lval testidx testidx_total)"
                suite_teardown
            fi
        }
        catch
        {
            rc=$?
        }
        edebug "Finished $(lval testname display_testname rc tries FAILURES)"

        # Verify there are no process or memory leaks. If so kill them and try again if that is permitted.
        #
        # NOTE: We skip checking for process and mount leaks if we're running multiple jobs at the same time as they
        # all share the same cgroup and working directory so we would have false positives. It doesn't really matter
        # because we will do a final check for process and mount leaks in `global_teardown`. And this isn't really an
        # issue anymore like it was 10 years ago as we're running inside docker now.
        if [[ ${jobs} -eq 0 ]]; then
            try
            {
                assert_no_process_leaks
                assert_no_mount_leaks
            }
            catch
            {
                rc+=$?
                eerror "${display_testname} FAILED due to process or mount leak."
            }
        fi

        if [[ ${rc} -eq 0 ]]; then
            break
        fi
    done

    if ! array_contains TEST_SUITES "${suite}"; then
        TEST_SUITES+=( "${suite}" )
    fi

    # If the test eventually passed (rc==0) but we had to try more than one time (tries > 0) then by definition
    # this is a flaky test.
    if [[ ${rc} -eq 0 && ${tries} -gt 0 ]]; then
        TESTS_FLAKY[$suite]+="${testname} "
        (( NUM_TESTS_FLAKY += 1 ))
    fi

    if [[ ${rc} -eq 0 ]]; then
        einfo "$(ecolor green)${display_testname} PASSED."
        TESTS_PASSED[$suite]+="${testname} "
        (( NUM_TESTS_PASSED += 1 ))
    else
        eerror "${display_testname} FAILED."
        TESTS_FAILED[$suite]+="${testname} "
        (( NUM_TESTS_FAILED += 1 ))
    fi

    eend --inline --inline-offset=${einfo_message_length} ${rc} &>>${ETEST_OUT}

    # Unit test provided teardown
    if declare -f teardown &>/dev/null ; then
        etestmsg "Calling test_teardown"
        $(tryrc -r=teardown_rc teardown)
    fi

    # Finally record the total runtime of this test
    TESTS_RUNTIME[${testname}]=$(( ${SECONDS} - ${start_time} ))

    # NOTE: If failfast is enabled don't DIE here just log the error for informational purposes and return.
    # etest already knows how to detect and report errors.
    if [[ ${failfast} -eq 1 && ${NUM_TESTS_FAILED} -gt 0 ]] ; then
        eerror "${display_testname} failed and failfast=1" &>>${ETEST_OUT}
    fi
}

run_etest_file()
{
    $(opt_parse \
        "testfile       | Name of the etest file to test." \
        "?functions_raw | Whitespace separated list of tests to run inside the testfile.")

    local testfilename
    testfilename=$(basename ${testfile})

    local functions
    array_init functions "${functions_raw}"

    if array_empty functions; then
        ewarn "No tests found in $(lval testfile)"
        return 0
    fi

    EMSG_PREFIX="" einfo "${testfile}" &>>${ETEST_OUT}

    # Run all tests for this suite
    local idx
    for idx in $(array_indexes functions); do

        local testfunc=${functions[$idx]}
        local testdir="${workdir}/${testfilename}/${testfunc}"

        run_single_test                                 \
            --testidx ${idx}                            \
            --testidx-total $(( ${#functions[@]} - 1 )) \
            --testdir "${testdir}"                      \
            --source "${testfile}"                      \
            "${testfunc}"

        # NOTE: If failfast is enabled don't DIE here just return. etest already knows how to detect and report errors.
        # No need to log the error here as it was logged inside run_single_test.
        if [[ ${failfast} -eq 1 && ${NUM_TESTS_FAILED} -gt 0 ]] ; then
            return 0
        fi

    done
}

find_matching_tests()
{
    # Expand tests to find all standalone executable scripts as well as any *.etest files.
    local all_tests=(
        $(find "${tests[@]}" \( -type f -or -type l \) -executable -not -name "*.etest" | sort || true)
        $(find "${tests[@]}" -type f -name "*.etest" | sort || true)
    )

    # Get a list of tests we should actually run.
    local testfile
    for testfile in "${all_tests[@]}"; do

        # If the test name matches a specified EXCLUDE, then skip it
        if [[ -n ${exclude} && ${testfile} =~ ${exclude} ]] ; then
            continue
        fi

        # If this is an etest, see if any of the functions inside the file match the filter.
        local has_matching_functions=false
        if [[ ${testfile} =~ \.etest$ ]]; then

            local function
            for function in $(grep "^ETEST_.*()" "${testfile}" | sed 's|().*||' || true); do

                if [[ -n ${exclude} && ${function} =~ ${exclude} ]]; then
                    continue
                fi

                if [[ -z ${filter} || ${testfile} =~ ${filter} || ${function} =~ ${filter} ]]; then
                    TEST_FUNCTIONS_TO_RUN[$testfile]+="${function} "
                    has_matching_functions=true
                fi
            done
        fi

        # If the filename matches a non-empty filter or we found functions that match the filter then run it.
        if [[ -z ${filter} || ${testfile} =~ ${filter} || ${has_matching_functions} == "true" ]]; then
            TEST_FILES_TO_RUN+=( "${testfile}" )
        fi
    done
}

# run_all_tests runs all test files discovered in `find_matching_tests`. This function has some intelligence to detect
# if we should run the tests serially or in parallel based on the value of --jobs. If that value is greater than 1, then
# all tests will be run in parallel via __run_all_tests_parallel. Otherwise the tests will be run serially via
# __run_all_tests_serially.
run_all_tests()
{
    OS="$(os_pretty_name)"
    if running_in_docker; then
        OS+=" (docker)"
    else
        OS+=" (native)"
    fi

    local etest_name="ETEST"
    if [[ -n "${name}" ]]; then
        etest_name+=" - \"${name//_/ }\""
    fi

    if [[ "${verbose}" -eq 1 ]]; then
        ebanner --uppercase "${etest_name}" OS debug exclude failfast failures filter jobs repeat=REPEAT_STRING timeout total_timeout verbose
    else
        ebanner --uppercase "${etest_name}" OS debug exclude failfast failures filter jobs repeat=REPEAT_STRING timeout total_timeout verbose &>>${ETEST_OUT}
    fi

    if [[ ${jobs} -gt 0 ]]; then
        elogfile_kill --all
        __run_all_tests_parallel
        cat "${logdir}"/jobs/*/output.log > "${ETEST_LOG}"
    else
        __run_all_tests_serially
    fi
}

# __run_all_tests_serially is a special internal helper function which is called by its parent function run_all_tests to
# run all tests one at a time in serial fashion.
__run_all_tests_serially()
{
    for testfile in "${TEST_FILES_TO_RUN[@]}"; do

        # Record start time of entire test suite
        local suite_start_time="${SECONDS}"

        # Run the test which could be a single test file or an entire suite (etest) file.
        if [[ "${testfile}" =~ \.etest$ ]]; then
            run_etest_file "${testfile}" "${TEST_FUNCTIONS_TO_RUN[$testfile]:-}"
        else
            run_single_test --testdir "${workdir}/$(basename ${testfile})" "${testfile}"
        fi

        if [[ ${failfast} -eq 1 && ${NUM_TESTS_FAILED} -gt 0 ]] ; then
             die "Failure encountered and failfast=1" &>${ETEST_OUT}
        fi

        SUITE_RUNTIME[$(basename ${testfile} .etest)]=$(( ${SECONDS} - ${suite_start_time} ))
    done
}

# __run_all_tests_parallel is a special internal helper function which is called by its parent function run_all_tests to
# run all tests in parallel. It uses the --jobs option to control how many test suites can be run in parallel at the
# same time. All test suites are essentially queued up into a runnable list. In has a `while true` loop where on each
# iteration it will launch a new backgrounded job up until it reaches our limit specified via --jobs. During that loop
# it will also wait on any previously backgrounded jobs and collect results about that job as they finish. It will also
# delay up to jobs_delay on each iteration to avoid hammering the system too much busy waiting for long running results.
__run_all_tests_parallel()
{
    local etest_jobs_running=()
    local etest_jobs_finished=()
    local etest_jobs_passed=()
    local etest_jobs_failed=()
    local etest_jobs_flaky=()
    local etest_jobs_queued=( ${TEST_FILES_TO_RUN[@]} )
    local etest_job_total=${#TEST_FILES_TO_RUN[@]}
    local etest_job_count=0
    declare -A pidmap=()
    efreshdir "${logdir}/jobs"
    local etest_eprogress_pids=()

    # Create eprogress status file
    local etest_progress_file="${logdir}/jobs/progress.txt"
    __update_jobs_progress_file
    if [[ ${jobs_progress} -eq 1 ]]; then
        einfo "Running etest ($(lval jobs))" &>> ${ETEST_OUT}
        eprogress                           \
            --style einfos                  \
            --file "${etest_progress_file}" \
            "Total: $(ecolor bold)${etest_job_total}$(ecolor reset)" &>> ${ETEST_OUT}

        # NOTE: We must explicitly empty out __EBASH_EPROGRESS_PIDS otherwise subsequent tests we run may kill this
        # eprogress and we want it to continue running. So we'll manually handle that here.
        array_copy __EBASH_EPROGRESS_PIDS etest_eprogress_pids
        trap_add "__EBASH_EPROGRESS_PIDS=( ${etest_eprogress_pids[*]} ); eprogress_kill -r=1 ${etest_eprogress_pids[*]} &>> ${ETEST_OUT}"
        __EBASH_EPROGRESS_PIDS=()
    fi

    while true; do

        __update_jobs_progress_file

        __process_completed_jobs

        if [[ ${failfast} -eq 1 && ${#etest_jobs_failed[@]} -gt 0 ]] ; then
            eerror "Failure encountered and failfast=1" &>> ${ETEST_OUT}
            break
        fi

        if [[ ${#etest_jobs_running[@]} -eq 0 && ${#etest_jobs_finished[@]} -ge ${etest_job_total} ]]; then
            edebug "All etest jobs finished"
            break
        elif [[ ${#etest_jobs_running[@]} -lt ${jobs} && ${etest_job_count} -lt ${etest_job_total} ]]; then
            __spawn_new_job
        else
            edebug "Throttling by $(lval jobs_delay)"
            sleep "${jobs_delay}"
        fi

    done

    array_copy etest_eprogress_pids __EBASH_EPROGRESS_PIDS
    eprogress_kill --rc=${#etest_jobs_failed[@]} &>> ${ETEST_OUT}

    if [[ ${jobs_progress} -eq 1 ]]; then
        __display_results_table &>> ${ETEST_OUT}
    fi
}

# __update_jobs_progress_file is a special internal helper function called by __run_all_tests_parallel to update the
# eprogress ticker file which we use to show the status of the parellel builds that are running asynchronously.
__update_jobs_progress_file()
{
    local tmpfile="${etest_progress_file}.tmp"

    {
        echo -n "   Queued: $(ecolor dim)$(( ${#etest_jobs_queued[@]} - ${etest_job_count} ))"
        ecolor reset

        echo -n "   Running: $(ecolor bold)${#etest_jobs_running[@]}"
        ecolor reset

        echo -n "   Passed: $(ecolor bold green)${#etest_jobs_passed[@]}"
        ecolor reset

        if [[ ${#etest_jobs_failed[@]} -gt 0 ]]; then
            echo -n "   Failed: $(ecolor bold red)${#etest_jobs_failed[@]}"
            ecolor reset
        fi

        if [[ ${#etest_jobs_flaky[@]} -gt 0 ]]; then
            echo -n "   Flaky: $(ecolor bold yellow)${#etest_jobs_flaky[@]}"
            ecolor reset
        fi

        echo -n " "

    } > "${tmpfile}"

    mv "${tmpfile}" "${etest_progress_file}"
}

# __process_completed_jobs is a special internal helper function called by __run_all_tests_parallel to process any jobs
# which may have run to completion. Essentially this captures the return code of the process and collects some stats
# about the job that are stored in global variables and then updates our internal job related lists accordingly.
#
# NOTE: The concurrent reading and writing of the global variables is safe as each job runs in an isolated subshell. The
# stats are specific to a single suite which is the granularity if our parallelism.
__process_completed_jobs()
{
    for pid in ${etest_jobs_running[*]:-}; do

        if process_running "${pid}"; then
            continue
        fi

        path=${pidmap[$pid]}

        # Capture PID and wait for the process to exit. Then capture all info from on-disk pack
        wait "${pid}" || true
        assert_exists "${path}/info.pack"
        local info=""
        pack_load info "${path}/info.pack"
        $(pack_import info)

        # Record it as a passing or failing job
        if [[ ${rc} -eq 0 ]]; then
            etest_jobs_passed+=( ${pid} )
        else
            etest_jobs_failed+=( ${pid} )
        fi

        etest_jobs_finished+=( ${pid} )
        array_remove etest_jobs_running ${pid}

        # Update global stats
        TESTS_RUNTIME[${suite}]=${runtime}
        SUITE_RUNTIME[${suite}]=$(( ${SUITE_RUNTIME[${suite}]:-0} + ${runtime} ))
        increment NUM_TESTS_EXECUTED ${num_tests_executed}
        increment NUM_TESTS_PASSED   ${num_tests_passed}
        increment NUM_TESTS_FAILED   ${num_tests_failed}
        increment NUM_TESTS_FLAKY    ${num_tests_flaky}

        # Update list of tests
        array_add TESTS_PASSED "${tests_passed}"
        array_add TESTS_FAILED "${tests_failed}"
        array_add TESTS_FLAKY  "${tests_flaky}"

        if ! array_contains TEST_SUITES "${suite}"; then
            TEST_SUITES+=( "${suite}" )
        fi

        if edebug_enabled; then
            einfo "Job finished: $(lval pid path etest_jobs_finished etest_job_total etest_job_count)"
            pack_to_json info | jq --color-output --sort-keys .
        fi

        if [[ ${jobs_progress} -eq 0 ]]; then
            cat "${path}/etest.out"  >> "${ETEST_OUT}"
        fi
    done
}

# __spawn_new_job is a special internal helper function to take a job from the queued list and run that job
# asynchronously in the background. We store off the pid and add it to an internal associative array `pidmap` which is
# used to be able to lookup the status of our backgrounded jobs later in `__process_completed_jobs`.
__spawn_new_job()
{
    local testfile=${etest_jobs_queued[${etest_job_count}]}
    edebug "Starting next job: ${testfile}"

    local jobpath="${logdir}/jobs/${etest_job_count}"
    mkdir -p "${jobpath}"

    # Run the test which could be a single test file or an entire suite (etest) file.
    (
        # Setup logfile for this background job and also set ETEST_OUT to a per-job file to collect etest output so we
        # can display it when the test completes (if ticker is turned off). The test output itself always goes to
        # /dev/null because elogfile is collecting the output for us and we'll aggregate it when etest is finished.
        elogfile "${jobpath}/output.log"
        trap_add "elogfile_kill --all"
        ETEST_OUT="${jobpath}/etest.out"
        TEST_OUT="/dev/null"

        # Initialize counters to 0. Otherwise they inherit the external incrementing value. We want to only get the
        # delta from this test run on its own.
        NUM_TESTS_EXECUTED=0
        NUM_TESTS_PASSED=0
        NUM_TESTS_FAILED=0
        NUM_TESTS_FLAKY=0

        # Capture suite name and start time.
        local suite=""
        local runtime="" start_time=${SECONDS}

        # Run the correct test runner depending on the type of file.
        if [[ "${testfile}" =~ \.etest$ ]]; then
            run_etest_file "${testfile}" "${TEST_FUNCTIONS_TO_RUN[$testfile]:-}"
            suite=$(basename "${testfile}" ".etest")
        else
            run_single_test --testdir "${workdir}/$(basename ${testfile})" "${testfile}"
            suite="$(basename "${testfile}")"
        fi

        # Capture all state from this test run and save it into a pack.
        local info=""
        pack_set info                                  \
            jobpath="${jobpath}"                       \
            job=$(basename "${jobpath}")               \
            rc="${NUM_TESTS_FAILED}"                   \
            runtime=$(( ${SECONDS} - ${start_time} ))  \
            suite="${suite}"                           \
            testfile="${testfile}"                     \
            num_tests_passed="${NUM_TESTS_PASSED}"     \
            num_tests_failed="${NUM_TESTS_FAILED}"     \
            num_tests_flaky="${NUM_TESTS_FLAKY}"       \
            num_tests_executed="${NUM_TESTS_EXECUTED}" \
            tests_passed="${TESTS_PASSED[$suite]:-}"   \
            tests_failed="${TESTS_FAILED[$suite]:-}"   \
            tests_flaky="${TESTS_FLAKY[$suite]:-}"     \

        pack_save info "${jobpath}/info.pack"

    ) &

    pid=$!
    echo "${pid}" > "${jobpath}/pid"
    pidmap[$pid]="${jobpath}"
    trap_add "ekill $pid 2>/dev/null"

    etest_jobs_running+=( ${pid} )
    increment etest_job_count
}

# Display a summary table of failing tests since there is no output on the screen to help them.
__display_results_table()
{
    echo
    echo

    declare -a table
    array_init_nl table "Job|Suite|Result|# Passed|# Failed|# Flaky|Output"

    local entry
    for entry in ${logdir}/jobs/*; do

        if [[ ! -e "${entry}/info.pack" ]]; then
            job="$(basename "${entry}")"
            status="$(ecolor dim red)ABORTED$(ecolor none)"
            array_add_nl table "${job}|-|${status}|-|-|-|${entry}/output.log"
            continue
        fi

        local info=""
        pack_load info "${entry}/info.pack"
        $(pack_import info)

        # Derive status to display with color annotations
        local status
        if [[ ${num_tests_failed} -ne 0 ]]; then
            status="$(ecolor bold red)FAILED$(ecolor none)"
        elif [[ ${num_tests_flaky} -ne 0 ]]; then
            status="$(ecolor bold yellow)FLAKY$(ecolor none)"
        else
            status="$(ecolor bold green)PASSED$(ecolor none)"
        fi

        # Annotate numver of failed and flaky tests with color
        if [[ ${num_tests_failed} -gt 0 ]]; then
            num_tests_failed="$(ecolor bold red)${num_tests_failed}$(ecolor none)"
        fi

        if [[ ${num_tests_flaky} -gt 0 ]]; then
            num_tests_flaky="$(ecolor bold yellow)${num_tests_flaky}$(ecolor none)"
        fi

        array_add_nl table "${job}|${suite}|${status}|${num_tests_passed}|${num_tests_failed}|${num_tests_flaky}|${entry}/output.log"

    done

    etable --title="$(ecolor bold green)Etest Results$(ecolor none)" "${table[@]}"
}

#-----------------------------------------------------------------------------------------------------------------------
#
# STATS
#
#-----------------------------------------------------------------------------------------------------------------------

create_vcs_info()
{
    declare -g VCS_INFO=""

    if [[ -d ".hg" ]] && command_exists hg; then
        pack_set VCS_INFO \
            type="hg"                                       \
            info="$(hg id --id)"                            \
            url="$(hg paths default)"                       \
            branch="$(hg branch)"                           \
            bookmark="$(hg book | awk '/ * / {print $2}')"  \
            commit="$(hg id --id)"

    elif [[ -d ".git" ]] && command_exists git && git rev-parse --is-inside-work-tree &>/dev/null; then
        pack_set VCS_INFO \
            type="git"                                                \
            info="$(git describe --abbrev=7 --always --tags --dirty)" \
            url="$(git config --get remote.origin.url)"               \
            branch="$(git rev-parse --abbrev-ref HEAD)"               \
            bookmark=""                                               \
            commit="$(git rev-parse --short=12 HEAD)"
    fi
}

create_summary()
{
    create_vcs_info

    {
        echo
        message="Finished testing $(pack_get VCS_INFO info)."
        message+=" $(( ${NUM_TESTS_PASSED} ))/${NUM_TESTS_EXECUTED} tests passed"
        message+=" in ${RUNTIME} seconds."

        if [[ ${NUM_TESTS_FAILED} -gt 0 ]]; then
            eerror "${message}"
        else
            einfo "${message}"
        fi
        echo

        if array_not_empty TESTS_FAILED; then
            eerror "FAILED TESTS:"
            for failed_test in $(echo "${TESTS_FAILED[@]}" | tr ' ' '\n') ; do
                echo "$(ecolor "red")      ${failed_test}" >&2
            done
            ecolor off >&2
        fi

        if array_not_empty TESTS_FLAKY; then
            ewarn "FLAKY TESTS:"
            for flaky_test in $(echo "${TESTS_FLAKY[@]}" | tr ' ' '\n') ; do
                echo "$(ecolor "yellow")      ${flaky_test}" >&2
            done
            ecolor off >&2
        fi

        # Create a summary file with relevant statistics
        if command_exists jq; then

			jq . <<-EOF > ${ETEST_JSON}
			{
				"numTestsExecuted": "${NUM_TESTS_EXECUTED}",
				"numTestsPassed": "${NUM_TESTS_PASSED}",
				"numTestsFailed": "${NUM_TESTS_FAILED}",
				"numTestsFlaky": "${NUM_TESTS_FLAKY}",
				"testsPassed": $(associative_array_to_json_split TESTS_PASSED),
				"testsFailed": $(associative_array_to_json_split TESTS_FAILED),
				"testsFlaky": $(associative_array_to_json_split TESTS_FLAKY),
				"runtime": "${RUNTIME} seconds",
				"datetime": "$(etimestamp_rfc3339)",
				"options": {
					"clean": "${clean}",
					"debug": "${debug}",
					"delete": "${delete}",
					"exclude": "${exclude}",
					"failfast": "${failfast}",
					"failures": "${failures}",
					"filter": "${filter}",
					"html": "${html}",
					"logdir": "${logdir}",
					"mount_ns": "${mount_ns}",
					"repeat": "${repeat}",
					"test_list": $(array_to_json test_list),
					"tests": $(array_to_json tests),
					"verbose": "${verbose}",
                    "workdir": "${workdir}"
				},
				"vcs": $(pack_to_json VCS_INFO)
			}
			EOF

            # Additionally display summary output to the terminal if requested
            if [[ "${summary}" -eq 1 ]]; then
                einfo "Summary"
                jq --color-output . ${ETEST_JSON}
            fi
        fi

    } |& tee -a ${ETEST_LOG} >&${ETEST_STDERR_FD}
}

create_xml()
{
    {
        printf '<?xml version="1.0" encoding="UTF-8" ?>\n'
        printf '<testsuites name="etest (%s)" tests="%d" failures="%d" time="%s">\n' \
            "$(etimestamp_rfc3339)" \
            "${NUM_TESTS_EXECUTED}" \
            "${NUM_TESTS_FAILED}"   \
            "${RUNTIME}"

        for suite in "${TEST_SUITES[@]}"; do

            local testcases_passed testcases_failed
            array_init testcases_passed "${TESTS_PASSED[$suite]:-}"
            array_init testcases_failed "${TESTS_FAILED[$suite]:-}"
            etestmsg "$(lval suite testcases_passed testcases_failed)"

            printf '<testsuite name="%s" tests="%d" failures="%d" time="%s">\n' \
                "${suite}"                                                      \
                $(( ${#testcases_passed[@]} + ${#testcases_failed[@]} ))        \
                ${#testcases_failed[@]}                                         \
                ${SUITE_RUNTIME[$suite]}

            local xml_lines=()
            local name

            # Add all passing tests
            for name in ${testcases_passed[*]:-}; do
                xml_lines+=( "$(printf '<testcase classname="%s" name="%s" time="%s"></testcase>\n' "${suite}" "${name}" "${TESTS_RUNTIME[$name]}")" )
            done

            # Add all failing tests
            for name in ${testcases_failed[*]:-}; do
                local failure_msg
                failure_msg="$(printf '<failure message="%s:%s failed" type="ERROR"></failure>' "${suite}" "${name}")"
                xml_lines+=( "$(printf '<testcase classname="%s" name="%s" time="%s">%s</testcase>\n' "${suite}" "${name}" "${TESTS_RUNTIME[$name]}" "${failure_msg}")" )
            done

            array_sort xml_lines
            etestmsg "$(lval xml_lines)"
            printf "%s\n" "${xml_lines[@]:-}"
            echo "</testsuite>"
        done

        echo "</testsuites>"

    } > ${ETEST_XML}
}

#-----------------------------------------------------------------------------------------------------------------------
#
# MAIN
#
#-----------------------------------------------------------------------------------------------------------------------

export ETEST_PID=$$

global_setup
trap_add global_teardown

# If clean only is requested exit immediately. The "clean" is done via global_setup and global_teardown.
if [[ ${clean} -eq 1 ]]; then
    exit 0
fi

# Global variables for state tracking
declare -ag TEST_FILES_TO_RUN
declare -Ag TEST_FUNCTIONS_TO_RUN
declare -ag TEST_SUITES=()
declare -Ag TESTS_PASSED=()
declare -Ag TESTS_FAILED=()
declare -Ag TESTS_FLAKY=()
declare -Ag SUITE_RUNTIME=()
declare -Ag TESTS_RUNTIME=()
declare -g  NUM_TESTS_EXECUTED=0
declare -g  NUM_TESTS_PASSED=0
declare -g  NUM_TESTS_FAILED=0
declare -g  NUM_TESTS_FLAKY=0

find_matching_tests

# If we are in print_only mode only report what we found and exit
if [[ ${print_only} -eq 1 ]]; then

    ebanner --uppercase "ETEST TESTS" OS exclude failfast filter repeat

    for testname in "${TEST_FILES_TO_RUN[@]}"; do
        einfo "${testname}"
        echo "${TEST_FUNCTIONS_TO_RUN[$testname]:-}" | tr ' ' '\n'
    done

    exit 0
fi

# If total timeout is requested thn create a background process that will sleep that amount of time and then kill our
# main etest process.
if [[ -n "${total_timeout}" && "${total_timeout}" != "infinity" ]]; then
    (
        sleep "${total_timeout}"

        eerror "ETEST exceeded $(lval total_timeout). Killing etest."

        ekill ${ETEST_PID}

        if cgroup_exists ${ETEST_CGROUP}; then
            cgroup_kill --signal=SIGKILL ${ETEST_CGROUP}
            cgroup_destroy --recursive ${ETEST_CGROUP}
        fi

        exit 124

    ) &>/dev/null &

    watcher_pid=$!

    trap_add "ekill ${watcher_pid} &>/dev/null" EXIT
fi

# Run all tests the requested number of times
for (( ITERATION=1; ITERATION<=${repeat}; ITERATION++ )); do
    REPEAT_STRING="${ITERATION}/${repeat}"
    run_all_tests
done

# Collect and report results
RUNTIME=$(( SECONDS - START_TIME ))
create_summary
create_xml

exit ${NUM_TESTS_FAILED}
